import os
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from groq import Groq

class PersianLawChatbot:
    def __init__(self):
        print("ğŸš€ Initializing Persian Law Chatbot...")
        
        # Check if knowledge base exists
        if not os.path.exists("./persian_law_db"):
            print("âŒ Knowledge base not found!")
            print("Please run create_knowledge_base.py first.")
            return
        
        # Initialize embedding model
        try:
            self.embedding_model = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
        except Exception as e:
            print(f"âŒ Error loading embedding model: {e}")
            return
        
        # Initialize vector store
        try:
            self.vector_store = Chroma(
                persist_directory="./persian_law_db",
                embedding_function=self.embedding_model,
                collection_name="persian_laws"
            )
        except Exception as e:
            print(f"âŒ Error loading vector database: {e}")
            return
        
        # Initialize Groq client
        try:
            self.groq_client = Groq(api_key=self.get_groq_api_key())
            self.available_models = self.get_available_models()
        except Exception as e:
            print(f"âŒ Error initializing Groq client: {e}")
            return
        
        self.chat_history = []
        print("âœ… Chatbot ready!")
    
    def get_groq_api_key(self):
        """Get Groq API key from environment or user input"""
        api_key = os.getenv("GROQ_API_KEY")
        if api_key:
            return api_key
        
        print("\nğŸ”‘ Groq API Key Setup:")
        print("1. Go to: https://console.groq.com/")
        print("2. Sign up for free account")
        print("3. Create API key")
        print("4. Enter your key below:")
        
        api_key = input("Enter your Groq API key: ").strip()
        
        if not api_key:
            print("âŒ No API key provided!")
            return None
        
        # Save to environment for future use
        os.environ["GROQ_API_KEY"] = api_key
        print("âœ… API key saved!")
        return api_key
    
    def get_available_models(self):
        """Get list of available Groq models"""
        try:
            models = self.groq_client.models.list()
            available_models = [model.id for model in models.data]
            print("ğŸ¤– Available Groq models:")
            for model in available_models:
                print(f"   - {model}")
            return available_models
        except Exception as e:
            print(f"âš ï¸ Could not fetch available models: {e}")
            # Return default models that are typically available
            return [
                "llama-3.1-8b-instant",  # Fast model, good for Persian
                "llama-3.1-70b-versatile",  # More powerful but slower
                "mixtral-8x7b-32768",
                "gemma2-9b-it"
            ]
    
    def select_model(self):
        """Select the best available model for Persian"""
        # Priority list for Persian language support
        preferred_models = [
            "llama-3.1-8b-instant",
            "llama-3.1-70b-versatile", 
            "mixtral-8x7b-32768",
            "gemma2-9b-it",
            "llama3-8b-8192"  # Fallback
        ]
        
        for model in preferred_models:
            if model in self.available_models:
                print(f"âœ… Selected model: {model}")
                return model
        
        # If no preferred models available, use the first available one
        if self.available_models:
            selected = self.available_models[0]
            print(f"âš ï¸ Using available model: {selected}")
            return selected
        
        # Fallback
        print("âš ï¸ Using default model: llama-3.1-8b-instant")
        return "llama-3.1-8b-instant"
    
    def find_relevant_context(self, question, k=4):
        """Find relevant law sections for the question"""
        try:
            docs = self.vector_store.similarity_search(question, k=k)
            context = "\n\n".join([doc.page_content for doc in docs])
            sources = list(set([doc.metadata.get('source', 'Unknown') for doc in docs]))
            return context, sources
        except Exception as e:
            print(f"Error searching database: {e}")
            return "", []
    
    def ask_question(self, question):
        """Ask a question about Persian law"""
        if not question.strip():
            return "Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ø³ÙˆØ§Ù„ Ù…Ø¹ØªØ¨Ø± Ù…Ø·Ø±Ø­ Ú©Ù†ÛŒØ¯.", []
        
        print("ğŸ” Searching in legal database...")
        context, sources = self.find_relevant_context(question)
        
        if not context:
            return "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·ÛŒ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ù‚ÙˆØ§Ù†ÛŒÙ† ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø´Ú©Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ Ù…Ø·Ø±Ø­ Ú©Ù†ÛŒØ¯.", []
        
        # Select the best available model
        model_name = self.select_model()
        
        # Enhanced system prompt in Persian
        system_prompt = """
        Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø­Ù‚ÙˆÙ‚ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ Ù…ØªØ®ØµØµ Ø¯Ø± Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§ÛŒØ±Ø§Ù† Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø­Ù‚ÙˆÙ‚ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙˆÙ† Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.

        Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù‡Ø§ÛŒ Ù…Ù‡Ù…:
        1. Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ùˆ Ø³Ø§Ø¯Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯
        2. Ù¾Ø§Ø³Ø® Ù‡Ø§ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙ† Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ (Context) Ø¨Ù†Ø§ Ú©Ù†ÛŒØ¯
        3. Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ…ØŒ ØªÙˆØ¶ÛŒØ­ Ù…Ø®ØªØµØ± Ùˆ Ù…ÙÛŒØ¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯
        4. Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØŒ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÙˆÛŒÛŒØ¯: "Ù¾Ø§Ø³Ø® Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø¯Ø± Ù…ØªÙˆÙ† Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        5. Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø¸Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ø§Ù…Ø§ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø±Ø³Ù…ÛŒ Ù†Ø¨Ø§Ø´ÛŒØ¯
        6. Ø¯Ø± Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ø¯Ù‚Øª Ùˆ Ø§Ø­ØªÛŒØ§Ø· Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯
        7. Ø¯Ø± ØµÙˆØ±Øª Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÛŒØŒ Ø´Ù…Ø§Ø±Ù‡ Ù…Ø§Ø¯Ù‡ Ø±Ø§ Ø°Ú©Ø± Ú©Ù†ÛŒØ¯

        Ù…ØªÙ† Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ù…Ø±ØªØ¨Ø·:
        {context}
        """
        
        formatted_system_prompt = system_prompt.format(context=context)
        
        try:
            print(f"ğŸ¤– Generating answer with {model_name}...")
            # Get response from Groq
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {
                        "role": "system", 
                        "content": formatted_system_prompt
                    },
                    {
                        "role": "user", 
                        "content": f"Ø³ÙˆØ§Ù„: {question}"
                    }
                ],
                model=model_name,
                temperature=0.3,
                max_tokens=1024,
                top_p=0.9
            )
            
            answer = chat_completion.choices[0].message.content
            
            # Update chat history
            self.chat_history.append({
                "question": question, 
                "answer": answer,
                "sources": sources,
                "model_used": model_name
            })
            
            return answer, sources
            
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {str(e)}"
            print(f"âŒ API Error: {e}")
            return error_msg, []

def main():
    print("ğŸ¤– PERSIAN LAW CHATBOT")
    print("=" * 50)
    
    try:
        chatbot = PersianLawChatbot()
        
        # Check if chatbot initialized successfully
        if not hasattr(chatbot, 'groq_client') or chatbot.groq_client is None:
            print("âŒ Chatbot initialization failed!")
            return
        
        print("\nğŸ¯ Ready to answer your law questions!")
        print("ğŸ’¡ Example questions:")
        print("   - 'Ù…ÙØ§Ø¯ Ø§ØµÙ„ÛŒ Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ú†ÛŒØ³ØªØŸ'")
        print("   - 'Ø´Ø±Ø§ÛŒØ· Ùˆ Ø¶ÙˆØ§Ø¨Ø· Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ú†Ù‡ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ù‡Ø³ØªÙ†Ø¯ØŸ'")
        print("   - 'Ù…Ø¬Ø§Ø²Ø§Øª Ù‡Ø§ÛŒ Ù¾ÛŒØ´ Ø¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ú†ÛŒØ³ØªØŸ'")
        print("\nØ¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ 'Ø®Ø±ÙˆØ¬' ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯")
        print("=" * 50)
        
        while True:
            try:
                user_question = input("\nğŸ§‘â€ğŸ’¼ Ø´Ù…Ø§: ").strip()
                
                if user_question.lower() in ['Ø®Ø±ÙˆØ¬', 'exit', 'quit', 'q']:
                    print("Ø®Ø¯Ø§Ù†Ú¯Ù‡Ø¯Ø§Ø±! ğŸ‘‹")
                    break
                
                if not user_question:
                    continue
                
                answer, sources = chatbot.ask_question(user_question)
                
                print(f"\nğŸ¤– Ø±Ø¨Ø§Øª: {answer}")
                if sources:
                    print(f"ğŸ“š Ù…Ù†Ø§Ø¨Ø¹: {sources}")
                print(f"ğŸ’¬ ({len(chatbot.chat_history)} Ø³ÙˆØ§Ù„ Ø¯Ø± Ø§ÛŒÙ† Ù†Ø´Ø³Øª)")
                    
            except KeyboardInterrupt:
                print("\n\nØ®Ø¯Ø§Ù†Ú¯Ù‡Ø¯Ø§Ø±! ğŸ‘‹")
                break
            except Exception as e:
                print(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
                
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª: {e}")

if __name__ == "__main__":
    main()